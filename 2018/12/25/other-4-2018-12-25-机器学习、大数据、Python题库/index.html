<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <script data-ad-client="ca-pub-2488174175014870" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script> <!-- google ad -->
    <meta name="google-site-verification" content="40lMg4eqLLbXoDcpN3h-cEnfmselbQ8tUzNvuC0IRIs" /><!-- google 站点认证 -->
    <meta name="baidu-site-verification" content="093lY4ziMu" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="description" content="A hexo theme">
    <meta name="keyword"  content="hexo, hexo-theme-lp">
    <link rel="shortcut icon" href="/img/ironman-draw.png">
    <!-- Place this tag in your head or just before your close body tag. -->
    <script async defer src="https://buttons.github.io/buttons.js"></script>
    <!--<link href='http://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>-->
    <title>
        
          机器学习、大数据、Python试题库 - Hexo-theme-lp
        
    </title>

    <link rel="canonical" href="https://flepeng.github.io/2018/12/25/other-4-2018-12-25-机器学习、大数据、Python题库/">

    <!-- Bootstrap Core CSS -->
    
<link rel="stylesheet" href="/css/bootstrap.min.css">


    <!-- Custom CSS --> 
    
        
<link rel="stylesheet" href="/css/dusign-light.css">

        
<link rel="stylesheet" href="/css/dusign-common-light.css">

        
<link rel="stylesheet" href="/css/font-awesome.css">

        
<link rel="stylesheet" href="/css/toc.css">

        <!-- background effects end -->
    
    
    <!-- Pygments Highlight CSS -->
    
<link rel="stylesheet" href="/css/highlight.css">


    
<link rel="stylesheet" href="/css/widget.css">


    
<link rel="stylesheet" href="/css/rocket.css">


    
<link rel="stylesheet" href="/css/signature.css">


    
<link rel="stylesheet" href="/css/fonts.googleapis.css">


    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">

    <!-- photography -->
    
<link rel="stylesheet" href="/css/photography.css">


    <!-- ga & ba script hoook -->
    <script></script>
<meta name="generator" content="Hexo 4.2.1"></head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- background effects start -->
    
    <!-- background effects end -->

	<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        
            
                background-image: linear-gradient(rgba(0, 0, 0, 0.3), rgba(0, 0, 0, 0.3)), url('/img/post-bg-debug.png')
                /*post*/
            
        
    }
    
    #signature{
        background-image: url('/img/signature/dusign.png');
    }
    
</style>

<header class="intro-header" >
    <!-- Signature -->
    <div id="signature">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                
                    <div class="post-heading">
                        <div class="tags">
                            
                              <a class="tag" href="/tags/#ML" title="ML">ML</a>
                            
                        </div>
                        <h1>机器学习、大数据、Python试题库</h1>
                        <h2 class="subheading"></h2>
                        <span class="meta">
                            Posted by Lepeng on
                            2018-12-25
                        </span>

                        
                            <div class="blank_box"></div>
                            <span class="meta">
                                Words <span class="post-count">8.9k</span> and
                                Reading Time <span class="post-count">31</span> Minutes
                            </span>
                            <div class="blank_box"></div>
                            <!-- 不蒜子统计 start -->
                            <span class="meta">
                                Viewed <span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span> Times
                            </span>
                            <!-- 不蒜子统计 end -->
                        

                    </div>
                

                </div>
            </div>
        </div>      
    </div>

    
    <div class="waveWrapper">
        <div class="wave wave_before" style="background-image: url('/img/wave-light.png')"></div>
        <div class="wave wave_after" style="background-image: url('/img/wave-light.png')"></div>
    </div>
    
</header>

	
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Lepeng</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                    

                        
                    

                        
                    

                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/categories/">Categories</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/archive/">Archives</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/tags/">Tags</a>
                        </li>
                        
                    
                    
                    
                    <li>
                        <a href="http://flepeng.com" target="_blank">chinese_blog</a>
                    </li>
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Main Content -->
    <!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <h3 id="（Python-ML）招聘基本要求："><a href="#（Python-ML）招聘基本要求：" class="headerlink" title="（Python-ML）招聘基本要求："></a>（Python-ML）招聘基本要求：</h3><ul>
<li>1、数据库Mysql及web框架Django</li>
<li>2、Python数据分析</li>
<li>3、Python的科学计算库、机器学习库等</li>
<li>4、基于Python的数据结构和算法研究</li>
<li>5、各种机器学习算法</li>
</ul>
<h3 id="应对策略：（一切都是基于Python）"><a href="#应对策略：（一切都是基于Python）" class="headerlink" title="应对策略：（一切都是基于Python）"></a>应对策略：（一切都是基于Python）</h3><ul>
<li>1、刷BAT的大数据（机器学习、深度学习）笔/面试题</li>
<li>2、加深对数据处理分析的流程熟悉，编写数据处理/分析流程及必要的手段</li>
<li>3、增强深度学习的系统性学习（轮廓）</li>
<li>4、使用Python的web框架Django，来构造一个真正的web项目（现成的），另外加深对Django特性的了解</li>
<li>5、在数据处理方面一定要有亮点如对CNN的理解和实践、对SVM的了解和实战项目</li>
<li>6、<em>不可三心二意，一心一意铺在数据分析和Python上</em></li>
<li>7、最后分门别类编写对应的心得和技术亮点（新点）</li>
<li>8、加强对英语的学习，提升听说能力（important）</li>
<li>9、基础的数据结构回顾，必要时可刷leatcode题库</li>
</ul>
<h3 id="BAT大数据题库刷记录"><a href="#BAT大数据题库刷记录" class="headerlink" title="BAT大数据题库刷记录"></a>BAT大数据题库刷记录</h3><ul>
<li><a href="https://blog.csdn.net/sinat_35512245/article/details/78796328" target="_blank" rel="noopener">学习地址</a></li>
<li><p>1、请简要介绍SVM</p>
<ul>
<li>SVM，全称support vector machine, 中文称之为支撑向量机。是一种面向数据的分类算法，它的目标是为了确定一个分类超平面，从而将数据分开。</li>
<li>扩展：SVM从简单到繁琐：线性可分SVM（硬隔离）、线性支持向量机（软隔离）、非线性SVM（核函数）。PS：了解什么是硬间隔、软间隔</li>
</ul>
</li>
<li><p>2、请简要介绍Tensorflow的计算图</p>
<ul>
<li>Tensorflow是一个通过计算图的形式来表述计算的编程过程，计算图也叫数据流图，可以把计算图看成一种有向图，Tensorflow中的每一个计算都是计算图上的节点，而节点之间的边描述计算之间的依赖关系。</li>
<li>Tensorflow的“计算图”分为2部分<ul>
<li>构造部分，包含计算流图</li>
<li>执行部分，通过session来执行图中的计算</li>
</ul>
</li>
</ul>
</li>
<li>3、请问GBDT和XGBoost的区别是什么？<ul>
<li>PS：我不知道这是做什么的-_-<a href="https://xijunlee.github.io/2017/06/03/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/" target="_blank" rel="noopener">学习地址</a></li>
</ul>
</li>
<li>4、在K-means或KNN，我们使用欧氏距离来计算最近的邻居之间的距离。为什么不用曼哈顿距离？<ul>
<li>曼哈顿距离只计算水平或垂直距离，有维度限制。另一方面，欧氏距离可用于任何空间的距离计算。因为数据可以存在于任何空间，欧氏距离是更行的选择。例如：国际象棋棋盘使用曼哈顿距离计算，因为它们的在各自的水平和垂直方向做的运动。</li>
</ul>
</li>
<li>5、百度2015机器学习笔试题<a href="http://www.itmian4.com/thread-7042-1-1.html" target="_blank" rel="noopener">链接</a></li>
<li>6、简单说说特征工程。<ul>
<li>互联网公司的数据挖掘工程师工作内容？<ul>
<li>研究各种算法，设计高大上模型…</li>
<li>深度学习的应用，N层神经网络…</li>
</ul>
</li>
<li>大部分复杂模型的算法都是数据科学家在做，大部分同学都是在跑数据、各种map-reduce、hive SQL、数据仓库搬砖、数据清洗、分析业务、找特征LR打天下<ul>
<li>关于LR（逻辑回归）。把LR从头到脚讲一遍。建模，现场数学推导，每种解法原理，正则化、LR和maxent模型之间的关系，LR为啥比线性回归好？<a href="http://blog.csdn.net/sinat_35512245/article/details/54881672" target="_blank" rel="noopener">学习链接</a></li>
</ul>
</li>
</ul>
</li>
<li>7、overfitting怎么解决？<ul>
<li>dropout、正则化（regularization）、batch normalization</li>
</ul>
</li>
<li>8、 LR和SVM的关系？<a href="http://blog.csdn.net/timcompp/article/details/62237986" target="_blank" rel="noopener">学习链接</a><ul>
<li>关系：<ul>
<li>1、LR和SVM都是用来处理分类问题，一般都用来处理线性二分问题</li>
<li>2、两个方法都可以增加不同的正则化项，如L1、L2等等。所以实验中，两种算法结果很接近</li>
</ul>
</li>
<li>区别：<ul>
<li>1、LR是参数模型，SVM是非参数模型。</li>
<li>2、从目标函数来看，区别在于LR采用logistical loss，SVM采用的是hinge loss。这两个损失函数的目的都是增加对分类影响较大的数据点的权重，减少与分类关系较小的数据点的权重。</li>
<li>3、SVM的处理方法是只考虑support vectors，LR通过非线性映射，大大减少了离分类平面远的点的权重，提升了与分类最相关的数据点的权重。</li>
<li>4、逻辑回归相对来说模型更简单，好理解，特别是大规模线性分类时比较方便。而SVM的理解和优化相对来说复杂一些，SVM转化为对偶问题后,分类只需要计算与少数几个支持向量的距离,这个在进行复杂核函数计算时优势很明显,能够大大简化模型和计算。</li>
<li>5、logic能做的SVM能做，但在准确率上，SVM可以做logic不能做的。</li>
</ul>
</li>
</ul>
</li>
<li>9、LR和线性回归的区别与联系？<ul>
<li>1、二者首先都是广义的线性回归</li>
<li>2、经典线性模型的优化目标函数是最小二乘，LR则是似然函数</li>
<li>3、另外线性回归在整个实数域范围内进行预测，敏感度一致，而分类范围，需要在[0,1]。逻辑回归就是一种减小预测范围，将预测值限定为[0,1]间的一种回归模型，因而对于这类问题来说，逻辑回归的鲁棒性比线性回归的要好。 </li>
<li>4、逻辑回归本质是一个线性回归模型，逻辑回归是以线性回归为理论支持的。但线性回归模型无法做到sigmoid的非线性形式，sigmoid可以轻松处理0/1分类问题。</li>
</ul>
</li>
<li>10、谈谈判别式模型和生成式模型？<ul>
<li>判别方法：由数据直接学习决策函数 Y = f(X)，或者由条件分布概率P(Y|X)作为预测模型，即判别模型。</li>
<li>生成方法：由数据学习联合概率密度分布函数P(Y|X)，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型。</li>
<li>由生成模型可以得到判别模型，但由判别模型得不到生成模型。</li>
<li>常见的判别模型：K近邻、SVM、决策树、感知机、线性判别分析（LDA）、线性回归、传统的神经网络、逻辑斯蒂回归、boostling、条件随机场。</li>
<li>常见的生成模型：朴素贝叶斯、隐马尔可夫模型、高斯混合模型、文档主题生成模型（LDA）、限制波尔兹曼机。</li>
</ul>
</li>
<li>11、L1和L2的区别<ul>
<li>L1范数（L1 norm）是指向量中各元素绝对值之和，也有个美称“稀疏规则算子”。</li>
<li>L2范数为一个向量中各个元素平方和的1/2次方，L2范数又被称为Euclidean范数或Frobenius范数</li>
<li>Lp范数为X向量中各元素绝对值p次方和的1/p次方。</li>
<li>在支持向量机学习过程中，L1范数实际是一种对于成本函数求解最优的过程，因此，L1范数正则化通过向成本函数中添加L1范数，使得学习得到的结果满足稀疏化，从而方便人类提取特征。 </li>
<li>L1范数可以使权值稀疏，方便特征提取。 </li>
<li>L2范数可以防止过拟合，提升模型的泛化能力。</li>
</ul>
</li>
<li>12、L1和L2正则先验分别服从什么分布？<ul>
<li>L1服从拉普拉斯分布，L2服从高斯分布</li>
</ul>
</li>
<li>13、CNN最成功的应用是在CV，那为什么NLP和Speech的很多问题也可以用CNN解出来？为什么AlphaGo里也用了CNN？这几个不相关的问题的相似性在哪里？CNN通过什么手段抓住了这个共性？<ul>
<li><a href="https://zhuanlan.zhihu.com/p/25005808" target="_blank" rel="noopener">答案地址</a></li>
</ul>
</li>
<li>14、为什么朴素贝叶斯如此“朴素”？<ul>
<li>因为它假定所有的特征在数据集中的作用是同样重要和独立的。正如我们所知，这个假设在现实世界中很不真实，因此，说朴素贝叶斯真的很“朴素”。</li>
</ul>
</li>
<li>15、Machine Learning中为何经常对数据做归一化？<ul>
<li>1）归一化后加快梯度下降求最优解的速度；</li>
<li>2）归一化后有可能提高精度。<a href="http://www.cnblogs.com/LBSer/p/4440590.html" target="_blank" rel="noopener">学习链接</a></li>
</ul>
</li>
<li>16、谈谈深度学习中的归一化问题？<br><a href="http://www.julyedu.com/video/play/69/686" target="_blank" rel="noopener">答案参考地址</a></li>
<li>17、简要说说一个完整ML项目流程。<ul>
<li>1）抽象成数学问题<ul>
<li>明确问题是进行机器学习的第一步。机器学习的训练过程通常都是一件非常耗时的工作，胡乱尝试成本很高。这里的抽象成数学问题，指的我们明确我们可以获得什么样的数据，目标是一个分类还是回归或者是聚类的问题。</li>
</ul>
</li>
<li>2）获取数据<ul>
<li>数据决定了机器学习结果的上限，而算法只是尽可能逼近这个上限；数据要有代表性，否则必然会过拟合。</li>
<li>而且对于分类问题，数据偏斜不能过于严重，不同类别的数据数量不要有数个数量级的差距。</li>
<li>而且还要对数据的量级有一个评估，多少个样本，多少个特征，可以估算出其对内存的消耗程度，判断训练过程中内存是否能够放得下。如果放不下就得考虑改进算法或者使用一些降维的技巧了。如果数据量实在太大，那就要考虑分布式了。</li>
</ul>
</li>
<li>3）特征预处理与特征选择<ul>
<li>良好的数据只有能够提取出良好的特征才能真正发挥效力</li>
<li>特征预处理、数据清洗是关键的步骤，往往能够使得算法的效果和性能得到明星提高。归一化、离散化、因子化、缺失值处理、去除共线性等，数据挖掘过程中很多时间就花在它们身上。这些工作简单可复制，收益稳定可预期，是机器学习的基础必备步骤。</li>
<li>筛选出显著特征、摒弃非显性特征，需要ML工程师反复理解业务。这对很多结果有决定性的影响。这需要运用特征有效性分析的相关技术，如相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法。</li>
</ul>
</li>
<li>4）训练模型与调优<ul>
<li>直到这一步才用到我们上面说的算法进行训练。现在很多算法都能够封装成黑盒供人使用。但是真正考验水平的是调整这些算法的（超）参数，使得结果变得更加优秀。这需要我们对算法的原理有深入的理解。理解越深，就越能发现问题的症结，提出良好的调优方案。</li>
</ul>
</li>
<li>5）模型诊断<ul>
<li>如何确定模型调优的方向与思路？这需要对模型进行诊断的技术。</li>
<li>过拟合、欠拟合判断是模型诊断中至关重要的的一步。常见的方法如交叉验证，绘制学习曲线等。过拟合的基本调优思路是增加数据量，降低模型复杂度。欠拟合的基本调优思路是提高特征数量和质量，增加模型复杂度。</li>
<li>误差分析也是ML至关重要的步骤。通过观察误差样本，全面分析误差产生的原因：是参数问题还是算法选择问题，是特征的问题还是数据本身的问题…</li>
<li>诊断后的模型需要进行调优，调优后的新模型需要重新进行诊断，这是一个反复迭代不断逼近的过程，需要不断地尝试，进而达到最优状态。</li>
</ul>
</li>
<li>6）模型融合<ul>
<li>一般来说，模型融合能使得效果有一定提升，而且效果很好。</li>
<li>工程上，主要提升算法准确度的方法是分别在模型的前端（特征清洗和预处理，不同的采样模式）与后端（模型融合）上下功夫。因为他们比较标准可复制，效果比较稳定。而直接调参的工作不会很多，毕竟大量数据训练起来太慢了，而且效果难以保证。</li>
</ul>
</li>
<li>7）上线运行<ul>
<li>这一部分内容主要跟工程实现的相关性比较大。工程上是结果导向，模型在线运行的效果直接决定模型的成败。不单纯包括其准确程度、误差等情况，还包括其运行的速度（时间复杂度）、资源消耗程度（空间复杂度）、稳定是否可接受。</li>
</ul>
</li>
<li>这些流程主要是工程实践上总结出的一些经验，并不是每个项目都包含完整的一个流程。</li>
</ul>
</li>
<li>18、new和malloc的区别？<ul>
<li>malloc()函数全称memory allocation，中文叫动态内存分配。<a href="https://www.cnblogs.com/fly1988happy/archive/2012/04/26/2470542.html" target="_blank" rel="noopener">学习链接</a></li>
</ul>
</li>
<li>19、hash冲突及解决办法？<ul>
<li>1）开放定址法</li>
<li>2）再哈希法；同时构造多个不同的哈希函数</li>
<li>3）链地址法：适合于经常进行插入和删除的情况</li>
<li>4）建立公共溢出区：将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表</li>
</ul>
</li>
<li>20、如何解决梯度消失和梯度膨胀？<ul>
<li>（1）梯度消失： <ul>
<li>根据链式法则，如果每一层神经元对上一层的输出的偏导乘上权重结果都小于1的话，那么即使这个结果是0.99，在经过足够多层传播之后，误差对输入层的偏导会趋于0。 </li>
<li>可以采用ReLU激活函数有效的解决梯度消失的情况。 </li>
</ul>
</li>
<li>（2）梯度膨胀： <ul>
<li>根据链式法则，如果每一层神经元对上一层的输出的偏导乘上权重结果都大于1的话，在经过足够多层传播之后，误差对输入层的偏导会趋于无穷大。</li>
</ul>
</li>
</ul>
</li>
<li>21、简单说下有监督学习和无监督学习的区别？<ul>
<li>有监督学习：对具有标记的训练样本进行学习，以尽可能对训练样本集外的数据进行分类预测。（LR、SVM、BP、RF、GBDT）</li>
<li>无监督学习：对未标记的样本进行训练学习，比如发现这样样本中的结构知识。（K-means,DL）</li>
</ul>
</li>
<li>22、了解正则化？<ul>
<li>正则化是针对过拟合而提出的，以为在求解模型最优的是一般优化最小的经验风险，现在在该经验风险上加入模型复杂度这一项（正则化项是模型参数向量的范数），并使用一个rate比率来权衡模型复杂度与以往经验风险的权重，如果模型复杂度越高，结构化的经验风险越大，现在的目标就变为了结构经验风险的最优化，可以防止模型训练过度复杂，有效的降低过拟合的风险。</li>
<li>奥卡姆剃刀原理，能很好的解释已知数据并且十分简单才是最好的模型。</li>
</ul>
</li>
<li>23、协方差和相关性有什么区别？<ul>
<li>相关性是协方差的标准格式。协方差本身很难比较。因为不同的变量有不同的度量方式，我们通过计算相关性来得到一个介于-1和1之间的值，这就忽略它们各自不同的度量。</li>
</ul>
</li>
<li>24、线性分类器与非线性分类器的区别以及优劣？<ul>
<li>若模型是参数的线性函数，并且存在线性分类面，那么就是线性分类器，否则不是。</li>
<li>常见线性分类器：LR、贝叶斯分类、单层感知机、线性回归。</li>
<li>常见的非线性分类器：决策树、RF、GBDT、多层感知机。</li>
<li>SVM两种都有（线性核还是非线性核：如高斯核）</li>
<li>线性分类器速度快、编程方便，但可能拟合效果不好。</li>
<li>非线性分类器编程复杂，但效果拟合能力强。</li>
</ul>
</li>
<li>25、数据的逻辑存储结构（如数组、队列、树、栈等）对于软件开发具有十分重要的影响，试从运行速度、存储效率、适用场景简要分析？</li>
<li>26、什么是分布式数据库？<ul>
<li>是在集中式数据库系统成熟技术的基础上发展起来的，但不是简单地把集中式数据库分散地实现，它具有自己的性质和特征。集中式数据库系统的许多概念和技术，如数据独立性、数据共享和减少冗余度、并发控制、完整性、安全性和恢复等在分布式数据库系统中都有不同的、更加丰富的内容。</li>
</ul>
</li>
<li>27\简单说说贝叶斯定理？<ul>
<li>条件概率（后验概率）就是事件A在另一个事件B已经发生条件下的发生概率。P(A|B), P(A|B)=P(A交B)/P(B)</li>
<li>联合概率：两个事件同时发生的概率。</li>
<li>边缘（际）概率：（又称先验概率）：A事件的边缘概率表示为P(A)</li>
<li>考虑一个问题：P(A|B)是在B发生情况下A发生的可能行？<ul>
<li>P(A|B) = P(B|A)P(A) / P(B)</li>
</ul>
</li>
</ul>
</li>
<li>28、简单说下sigmoid激活函数<ul>
<li>常用的非线性激活函数有sigmoid、tanh、relu等等，前两者比较常见于全连接层，后者常见于卷积层。</li>
</ul>
</li>
<li>29、什么是卷积？<ul>
<li>对于图像（不同的数据窗口数据）和滤波矩阵（一组固定的权重：因为每个神经元的多个权重固定，所以又可以看做一个恒定的滤波器filter）做内积（逐各元素相乘在求和）的操作就是所谓的「卷积」操作，也是卷积神经网络的名字来源。</li>
</ul>
</li>
<li>30、什么是CNN的池化pool层？<ul>
<li>池化，简而言之，即取平均或最大，如：</li>
<li>[1 1 2 4]  —&gt; [6 8]</li>
<li>[5 6 7 8]</li>
</ul>
</li>
<li>31、简述什么是生成对抗网络？<ul>
<li>GAN之所以是对抗的，是因为GAN的内部是竞争关系，一方叫generator（生成模型），它的主要工作是生成图片，并且尽量使得其看上去是来自于训练样本的。另一方是discriminator（判断模型），其目标是判断输入图片是否属于真实训练样本。</li>
</ul>
</li>
<li>32、哪些机器算法不需要做归一化处理？<ul>
<li>概率模型不需要归一化，因为它们不关心变量的值，而是关心变量的分布和变量之间的条件概率，如决策树、RF。而像Adaboost、GBDT、XGBoost、SVM、LR、KNN、KMeans之类的最优问题需要归一化。</li>
</ul>
</li>
<li>33、说说梯度下降<ul>
<li><a href="http://www.cnblogs.com/LeftNotEasy/archive/2010/12/05/mathmatic_in_machine_learning_1_regression_and_gradient_descent.html" target="_blank" rel="noopener">学习地址</a></li>
</ul>
</li>
<li>34、梯度下降法找到的一定是下降最快的方向？<ul>
<li>并不一定是下降最快的方向，它只是目标函数在当前的点的切平面上下降最快的方向。</li>
</ul>
</li>
<li>35、说说随机梯度下降法的问题和挑战？<ul>
<li>困难：<ul>
<li>1）梯度的计算</li>
<li>2）学习率的选择，学习率太小，导致算法收敛太慢，学习率选择过大容易导致算法不收敛。</li>
</ul>
</li>
</ul>
</li>
<li>36、什么是最小二乘法？<ul>
<li>最小二乘法（又称最小平方法）是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。利用最小二乘法可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间误差的平方和为最小。</li>
</ul>
</li>
<li>37、说说Python到底是什么样的语言？<a href="http://nooverfit.com/wp/15%E4%B8%AA%E9%87%8D%E8%A6%81python%E9%9D%A2%E8%AF%95%E9%A2%98-%E6%B5%8B%E6%B5%8B%E4%BD%A0%E9%80%82%E4%B8%8D%E9%80%82%E5%90%88%E5%81%9Apython%EF%BC%9F/" target="_blank" rel="noopener">答案解析</a><ul>
<li>Python是解释型语言，Python运行前不需要编译。</li>
<li>Python是动态的，不需要在声明变量时指定类型。</li>
<li>面向对象，允许定义类并可以继承和组合，Python没有访问标识符，如C++中的private、public</li>
<li>Python中函数是一等公民，它们可以被直接赋值，从其他函数返回值，并传递函数对象，类不是一等公民。</li>
<li>Python代码很快，但跑起来会比编译型语言慢，但Python允许使用C扩展写程序，所以瓶颈可以处理。</li>
<li>Python的应用场景很多，web开发，自动化，科学建模，大数据应用等。它也经常被视为胶水语言。</li>
<li>Python可以简化工作，使得程序员能过关心如何重写代码而不是详细的看一遍底层实现</li>
</ul>
</li>
<li>38、Python和多线程。是不是个好主意？列举你觉得可以让Python代码并行运行的方法？<ul>
<li>Python实际上不允许多线程。它有一个threading包但是如果你想加快代码运行速度，或者想并行运行，这不是一个好主意。Python有一个机制叫全局解释器锁（GIL）。GIL保证每次只有一个线程在解释器中跑。一个线程获得GIL，之后再交给下一个线程。所以，看起来是多个线程在同时跑，但是实际上每个时刻只有CPU核在跑一个线程，没有真正利用多个CPU核跑多个线程。就是说，多个线程在抢着跑一个CPU核。</li>
<li>但是还是有使用threading包的情况的。比如你真的想跑一个可以线程间抢占的程序，看起来是并行的。或者有很长时间的IO等待线程，这个包就会有用。但是threading包不会使用多核去跑代码。</li>
<li>真正的多核多线程可以通过多进程，一些外部库如Spark和Hadoop，或者用Python代码去调用C方法等等来实现。</li>
</ul>
</li>
<li>39、怎么对你的代码进行跟踪、协同写代码？<ul>
<li>版本号控制！只是关键，你应该很高兴地告诉他们你怎么使用git的，当然svn也是。</li>
</ul>
</li>
<li>40、 修饰器的概念？</li>
<li>41、Python的垃圾回收机制？<ul>
<li>Python在内存中维护对象的引用次数。如果一个对象的引用次数变为0，垃圾回收机制会回收这个对象作为他用。</li>
<li>有时候会有“引用循环”的事情发生。垃圾回收器定期检查回收内存。一个例子是，如果你有两个对象 o1 和 o2，并且o1.x == o2 and o2.x == o1. 如果 o1 和 o2 都没有被其他对象使用，那么它们都不应该存在。但是它们的应用次数都是1，垃圾回收不会起作用。</li>
<li>一些启发算法可以用来加速垃圾回收。比如，最近创建的对象更可能是无用的。用创建时间来度量对象的生命时长，生命越长，越可能是更有用的对象。</li>
</ul>
</li>
<li>42、其他Python面试题<ul>
<li><a href="http://www.cnblogs.com/tom-gao/p/6645859.html" target="_blank" rel="noopener">学习连接</a></li>
</ul>
</li>
<li>43、请写出一段Python代码实现删除一个list里面的重复元素。<ul>
<li>要求：使用set函数，set(list);使用字典函数；</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">0</span>]</span><br><span class="line">b = &#123;&#125;</span><br><span class="line">b = b.fromkeys(a)</span><br><span class="line">c = list(b.keys())</span><br><span class="line">c</span><br></pre></td></tr></table></figure>
<ul>
<li>44、编程用sort进行排序，然后从最后一个元素开始判断。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">10</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">0</span>,<span class="number">3</span>]</span><br><span class="line">a.sort()</span><br><span class="line">last=a[<span class="number">-1</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(a)<span class="number">-2</span>,<span class="number">-1</span>,<span class="number">-1</span>):</span><br><span class="line">    <span class="keyword">if</span> last==a[i]:</span><br><span class="line">        <span class="keyword">del</span> a[i]</span><br><span class="line">    <span class="keyword">else</span>: last=a[i]</span><br><span class="line">    print(a)</span><br></pre></td></tr></table></figure>
<ul>
<li>45、Python里面如何生成随机数？<ul>
<li>random模块<ul>
<li>随机整数：random.randint(a,b):返回随机整数x, a&lt;=x&lt;=b</li>
<li>random.randrange(start,stop,[step])</li>
<li>随机实数：random.random()：返回（0，1）之间的浮点数</li>
<li>random.uniform(a,b)：返回指定范围内的浮点数</li>
</ul>
</li>
</ul>
</li>
<li>46、说说常见的损失函数<ul>
<li>对于给定的输入X,由f(X)输出相应的Y，这个输出的预测值f(X)与真实的Y可能一致，也可能不一致（误差在所难免），用一个损失函数来度量预测错误的程度，这个损失函数记住L(Y, f(x))</li>
<li>常用的损失函数有：<ul>
<li>0-1损失函数</li>
<li>平方损失函数</li>
<li>对数损失函数</li>
</ul>
</li>
</ul>
</li>
<li>47、简单介绍逻辑回归LR<ul>
<li>目的：从特征学习出一个0/1分类模型，而这个模型是将特性的线性组合作为自变量，由于自变量的取值范围是负无穷到正无穷。因此使用LR函数（或称为sigmoid函数）将自变量映射到（0，1）上，映射后的值被认为是属于y=1的概率。</li>
</ul>
</li>
<li>48、以下哪些方法不可以直接对文本分类<ul>
<li>决策树、SVM、KNN都可以直接对文本分类；但Kmeans不行，Kmeans是聚类方法，无监督学习</li>
</ul>
</li>
<li>49、Kmeans的复杂度？<ul>
<li>时间复杂度：O(tKmn)，其中，t为迭代次数，K为簇的数目，m为记录数，n为维数</li>
<li>空间复杂度：O((m+K)n)</li>
</ul>
</li>
<li>50、影响聚类算法结果的主要因素有<ul>
<li>分类标准、特征选择、模式相似性测度</li>
</ul>
</li>
<li>51、<ul>
<li>（1）模式识别中，马氏距离较之欧氏距离的优点：尺度不变形、考虑模式的分布</li>
<li>（2）影响基本K均值算法的主要因素：样本输入顺序、模式相似性测度、聚类准则</li>
<li>（3）在统计模式分类问题中，当先验概率未知时，可以使用 「最小最大损失准则」、「N-P判决」</li>
<li>（4）欧氏距离具有「平移不变性」「旋转不变性」</li>
<li>（5）马氏距离具有「尺度缩放不变性」「不受量纲影响的特性」「平移不变性」「旋转不变性」</li>
</ul>
</li>
<li>52、你有哪些DL（RNN、CNN）调参经验？<ul>
<li><a href="https://www.zhihu.com/question/41631631" target="_blank" rel="noopener">学习地址</a></li>
</ul>
</li>
<li>53、说说RNN（循环神经网络）原理<ul>
<li><a href="http://blog.csdn.net/heyongluoyao8/article/details/48636251" target="_blank" rel="noopener">相关题目1</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/28054589" target="_blank" rel="noopener">相关题目2</a></li>
</ul>
</li>
<li>54、当机器学习性能遭遇瓶颈时，如何优化？<ul>
<li>可以从4个方面进行尝试：基于数据、借助算法、用算法调参、借助模型融合。谈多谈少看经验和心得。</li>
<li><a href="http://blog.csdn.net/han_xiaoyang/article/details/53453145" target="_blank" rel="noopener">机器学习改善备忘录</a></li>
</ul>
</li>
<li>55、做过什么样的机器学习项目？比如如何从零构建一个推荐系统？<ul>
<li>看个人项目了，所以说还是要有实战的经验。「数据分析项目」</li>
</ul>
</li>
<li>56、数据预处理<ul>
<li>（1）缺失值，填充缺失值fillna：<ul>
<li>1）离散：None</li>
<li>2）连续：均值</li>
<li>3）缺失值太多，则直接去除该列</li>
</ul>
</li>
<li>（2）连续值：离散化。有的模型（如决策树）需要离散化</li>
<li>（3）对定量特征二值化。核心在于设定一个阈值，大于阈值设置为1，小于等于阈值赋值为0.</li>
<li>（4）皮尔逊相关系数，去除高度相关的列</li>
</ul>
</li>
<li>57、如何进行特征选择？<ul>
<li>特征选择是一个重要的数据预处理过程，主要有两个原因：<ul>
<li>一是减少特征数量、降维，使模型泛化能力更强，减少过拟合;</li>
<li>二是增强对特征和特征值之间的理解。</li>
</ul>
</li>
<li>常用的特征选择方式：<ul>
<li>去除方差较小的特征</li>
<li>正则化。L1正则化能够生成稀疏的模型。L2正则化的表现更加稳定，由于有用的特征往往对应的系数飞零。</li>
<li>随机森林，对于分类问题，通常采用基尼不纯度或者信息增益，对于回归问题，通常采用的是方差或者最小二乘拟合。一般不需要feature engineering、调参等繁琐的步骤。它的两个主要问题，1是重要的特征有可能得分很低（关联特征问题），2是这种方法对特征变量类别多的特征越有利（偏向问题）。</li>
<li>稳定性选择。是一种基于二次抽样和选择算法相结合较新的方法，选择算法可以是回归、SVM或其他类似的方法。它的主要思想是在不同的数据子集和特征子集上运行特征选择算法，不断的重复，最终汇总特征选择结果，比如可以统计某个特征被认为是重要特征的频率（被选为重要特征的次数除以它所在的子集被测试的次数）。理想情况下，重要特征的得分会接近100%。稍微弱一点的特征得分会是非0的数，而最无用的特征得分将会接近于0。</li>
</ul>
</li>
</ul>
</li>
<li>58、你知道有哪些数据处理和特征工程的处理？<br><img src="https://img-blog.csdn.net/20171214121831941?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzU1MTIyNDU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="特征工程"></li>
<li>59、SVD和PCA<ul>
<li>PCA的理念是使得数据投影后的方差最大，找到这样一个投影，满足方差最大的条件即可。而经过去除均值的操作后，就可以使用SVD分解来求解这样的一个投影向量，选择特征最大的方向。</li>
</ul>
</li>
<li>60、数据不平衡问题？<ul>
<li>这主要是由数据的分布不平衡造成的，解决方案如下：<ul>
<li>1）采样，对小样本加噪声采样，对大样本进行下采样 </li>
<li>2）进行特殊的加权，如在Adaboost中或者SVM中 </li>
<li>3）采用对不平衡数据集不敏感的算法 </li>
<li>4）改变评价标准：用AUC/ROC来进行评价 </li>
<li>5）采用Bagging/Boosting/Ensemble等方法 </li>
<li>6）考虑数据的先验分布</li>
</ul>
</li>
</ul>
</li>
<li>61、简述神经网络的发展<ul>
<li>MP模型+sgn——&gt;单层感知机（只能线性）+sgn——&gt;Minsky 低谷 ——&gt;多层感知机+BP+Sigmoid——&gt;(低谷) ——&gt;深度学习+Pretraining+ReLU/Sigmoid</li>
</ul>
</li>
<li>62、深度学习常用方法<ul>
<li><a href="http://blog.csdn.net/u010496169/article/details/73550487" target="_blank" rel="noopener">参考地址</a></li>
</ul>
</li>
<li>63、卷积神经网络可以对一个输入进行多种变换（旋转、平移、缩放），这表示正确吗？<ul>
<li>把数据传入神经网络之前需要做一系列的数据预处理（也就是旋转、平移、缩放）工作，神经网络本身不能完成这些变换。</li>
</ul>
</li>
<li>64、常见的监督学习算法有哪些？<ul>
<li>感知机、SVM、人工神经网络、决策树、逻辑回归</li>
</ul>
</li>
<li>65、数据清理中，处理缺失值的方法？<ul>
<li>估算、整例删除、变量删除、成对删除</li>
</ul>
</li>
<li>66、试推导样本空间中任意点x到超平面（w，b）的距离公式<br><img src="https://img-blog.csdn.net/20171214141457046?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzU1MTIyNDU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="超平面距离"></li>
<li>67、CNN常用的几个模型<br><img src="https://img-blog.csdn.net/20171214141903341?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzU1MTIyNDU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="CNN模型"></li>
<li>68、带核函数的SVM为什么能分类非线性问题？<ul>
<li>核函数的本质就是两个函数的内积，而这个函数在svm中可以表示成对输入值的高维映射。注意核并不是直接对应映射，核只不过是一个内积。（感觉答非所问）</li>
</ul>
</li>
<li>69、常用核函数即核函数条件<ul>
<li>核函数选择的时候应该从线性核开始，而且在特征很多的情况下没有必要选择高斯核，应该从简单到难的选择模型。我们通常说的核函数指的是正定和函数，其充要条件是对于任意的x属于X，要求K对应的Gram矩阵要是半正定矩阵。<br>RBF核径向基，这类函数取值依赖于特定点间的距离，所以拉普拉斯核其实也是径向基核。<br>线性核：主要用于线性可分的情况<br>多项式核</li>
</ul>
</li>
<li>70、逻辑回归相关问题<ul>
<li>公式一定会推</li>
<li>LR基本概念，最好从广义线性模型的角度分析，逻辑回归是假设y服从Bernoulli分布。</li>
<li>L1、L2范式</li>
<li>LR与SVM的比较</li>
<li>LR与随机森林的比较</li>
<li>常用优化方法</li>
</ul>
</li>
<li>71、什么是共线性，跟过拟合有什么联系？<ul>
<li>共线性：多变量线性回归中，变量之间由于存在高度相关关系而使回归估计不准确。<br>共线性会造成冗余，导致过拟合。</li>
<li>解决方法：排除变量的相关性或加入权重正则。</li>
</ul>
</li>
<li>72、机器学习中的正负样本<ul>
<li>在分类问题中，这个问题相对好理解一点，比如人脸识别中的例子，正样本很好理解，就是人脸的图片，负样本的选取就与问题场景相关，具体而言，如果你要进行教室中学生的人脸识别，那么负样本就是教室的窗子、墙等等，也就是说，不能是与你要研究的问题毫不相关的乱七八糟的场景图片，这样的负样本并没有意义。负样本可以根据背景生成，有时候不需要寻找额外的负样本。一般3000-10000的正样本需要5，000,000-100,000,000的负样本来学习，在互金领域一般在入模前将正负比例通过采样的方法调整到3:1-5:1。</li>
</ul>
</li>
<li>73、对于维度极低的特征，选择线性还是非线性分类器？<ul>
<li>非线性分类器，低维空间可能很多特征都跑到一起了，导致线性不可分。<ul>
<li>1.如果特征的数量很大，跟样本数量差不多，这时候选用LR或者是Linear Kernel的SVM。 </li>
<li>2.如果特征的数量比较小，样本数量一般，不算大也不算小，选用SVM+Gaussian Kernel。 </li>
<li>3.如果特征的数量比较小，而样本数量很多，需要手工添加一些特征变成第一种情况。</li>
</ul>
</li>
</ul>
</li>
<li>74、SVM、LR和决策树的对比<ul>
<li>模型复杂度：SVM支持核函数，可处理线性非线性问题;LR模型简单，训练速度快，适合处理线性问题;决策树容易过拟合，需要进行剪枝。 </li>
<li>损失函数：SVM hinge loss; LR L2正则化; Adaboost 指数损失。 </li>
<li>数据敏感度：SVM添加容忍度对outlier不敏感，只关心支持向量，且需要先做归一化; LR对远点敏感。 </li>
<li>数据量：数据量大就用LR，数据量小且特征少就用SVM非线性核。</li>
</ul>
</li>
<li>75、简述KNN最近邻分类算法的过程？<ul>
<li>1计算训练样本和测试样本中每个样本点的距离（常用距离欧氏距离、马氏距离）</li>
<li>2对上面所有的距离进行排序；</li>
<li>3选前K个最小距离的样本；</li>
<li>4根据这K个样本的标签进行投票，得到最后的分类类别。</li>
</ul>
</li>
<li>76、特征向量的归一化方法有哪些？<ul>
<li>线性函数转换</li>
<li>对数函数转换</li>
<li>反余切函数转换</li>
<li>减去均值，除以方差</li>
</ul>
</li>
<li>77、优化算法及其优缺点？<ul>
<li>温馨提示：在回答面试官的问题的时候，往往将问题往大的方面去回答，这样不会陷于小的技术上死磕，最后很容易把自己嗑死了。 </li>
<li>1）随机梯度下降：优点：可以一定程度上解决局部最优解的问题  ；   缺点：收敛速度较慢</li>
<li>2）批量梯度下降：优点：容易陷入局部最优解   ；  缺点：收敛速度较快 </li>
<li>3）mini_batch梯度下降：综合随机梯度下降和批量梯度下降的优缺点，提取的一个中和的方法。</li>
<li>4）牛顿法：牛顿法在迭代的时候，需要计算Hessian矩阵，当维度较高的时候，计算 Hessian矩阵比较困难。</li>
<li>5）拟牛顿法：拟牛顿法是为了改进牛顿法在迭代过程中，计算Hessian矩阵而提取的算法，它采用的方式是通过逼近Hessian的方式来进行求解。</li>
</ul>
</li>
</ul>
<blockquote>
<p>本文首发<a href="https://ZhaoYLong.github.io" target="_blank" rel="noopener">YunLong-Blog</a>，题目摘自CSDN、博客园等博客平台。</p>
</blockquote>

                
                <hr>
                <!-- Pager -->
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2019/01/06/other-4-2019-01-06-Java并发基础梳理/" data-toggle="tooltip" data-placement="top" title="Java并发基础梳理">&larr; Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2018/12/18/other-3-2018-12-18-Sort-Algorithm/" data-toggle="tooltip" data-placement="top" title="八种常用排序算法">Next Post &rarr;</a>
                    </li>
                    
                </ul>

                <!-- tip start -->
                

                
                <div class="comment_notes">
                    <p>
                        study well and make progress every day; study well and progress every day; study hard and make progress every day.
                    </p>
                </div>
                
                <!-- tip end -->

                <!-- Music start-->
                
                <!-- Music end -->

                <!-- Sharing -->
                
                <div class="social-share"  data-wechat-qrcode-helper="" align="center"></div>
                <!--  css & js -->
                <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">
                <script src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>
                
                <!-- Sharing -->

                <!-- gitment start -->
                
                <!-- gitment end -->

                <!-- 来必力City版安装代码 -->
                
                <!-- City版安装代码已完成 -->

                <!-- disqus comment start -->
                
                <!-- disqus comment end -->
            </div>
            
            <!-- Tabe of Content -->
            <!-- Table of Contents -->

    
      
        <aside id="sidebar">
          <div id="toc" class="toc-article">
          <strong class="toc-title">Contents</strong>
          
            
              <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#（Python-ML）招聘基本要求："><span class="toc-nav-number">1.</span> <span class="toc-nav-text">（Python-ML）招聘基本要求：</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#应对策略：（一切都是基于Python）"><span class="toc-nav-number">2.</span> <span class="toc-nav-text">应对策略：（一切都是基于Python）</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#BAT大数据题库刷记录"><span class="toc-nav-number">3.</span> <span class="toc-nav-text">BAT大数据题库刷记录</span></a></li></ol>
            
          
          </div>
        </aside>
      
    

                
            <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <!-- no hr -->
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                       
                          <a class="tag" href="/tags/#ML" title="ML">ML</a>
                        
                    </div>
                </section>
                

                <!-- Friends Blog -->
                
                <hr>
                <h5>FRIENDS</h5>
                <ul class="list-inline">

                    
                        <li><a href="https://blog.csdn.net/fenglepeng" target="_blank">Feng Lepeng&#39;s CSDN</a></li>
                    
                </ul>
                
            </div>
        </div>
    </div>
</article>




<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'hover',
          placement: 'left',
          icon: 'ℬ'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>


<style  type="text/css">
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">

                

                

                

                

                

                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy;
                    <a href="https://beian.miit.gov.cn/" target="_blank" rel="noopener">京ICP备18055501号-2</a>;
                    Feng Lepeng 2021
                    <br>
                    Powered by 
                    <a href="https://github.com/dusign/hexo-theme-snail" target="_blank" rel="noopener">
                        <i>hexo-theme-snail</i>
                    </a> | 
                    <iframe name="star" style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0"
                        width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=flepeng&repo=hexo-theme-lp&type=star">
                    </iframe>
                </p>
            </div>
        </div>
    </div>

</footer>

<!-- jQuery -->

<script src="/js/jquery.min.js"></script>


<!-- Bootstrap Core JavaScript -->

<script src="/js/bootstrap.min.js"></script>


<!-- Custom Theme JavaScript -->

<script src="/js/hux-blog.min.js"></script>


<!-- Search -->

<script src="/js/search.js"></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("https://flepeng.github.io/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->


<script>
    // dynamic User by Hux
    var _gaId = 'UA-XXXXXXXX-X';
    var _gaDomain = 'yoursite';

    // Originial
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>




<!-- Baidu Tongji -->


<!-- Search -->

    <script type="text/javascript">      
        var search_path = "search.xml";
        if (search_path.length == 0) {
            search_path = "search.xml";
        }
    var path = "/" + search_path;
    searchFunc(path, 'local-search-input', 'local-search-result');
    </script>


<!-- busuanzi -->
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>






	<a id="rocket" href="#top" class=""></a>
	<script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
    <script type="text/javascript" src="/js/toc.js?v=1.0.0" async=""></script>

    
        <!-- background effects line -->
        

        
            <script type="text/javascript" src="/js/mouse-click.js" content='[&#34;🌱&#34;,&#34;just do it&#34;,&#34;🍀&#34;]' color='[&#34;rgb(121,93,179)&#34; ,&#34;rgb(76,180,231)&#34; ,&#34;rgb(184,90,154)&#34;]'></script>
        

        <!-- background effects end -->
    

    <!--<script size="50" alpha='0.3' zIndex="-999" src="/js/ribbonStatic.js"></script>-->
    
        <script src="/js/ribbonDynamic.js"></script>
    
</body>

</html>
